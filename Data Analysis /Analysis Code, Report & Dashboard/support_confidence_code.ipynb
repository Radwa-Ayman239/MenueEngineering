{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# This is a sample Jupyter Notebook\n",
    "\n",
    "Below is an example of a code cell. \n",
    "Put your cursor into the cell and press Shift+Enter to execute it and select the next one, or click 'Run Cell' button.\n",
    "\n",
    "Press Double Shift to search everywhere for classes, files, tool windows, actions, and settings.\n",
    "\n",
    "To learn more about Jupyter Notebooks in PyCharm, see [help](https://www.jetbrains.com/help/pycharm/ipython-notebook-support.html).\n",
    "For an overview of PyCharm, go to Help -> Learn IDE features or refer to [our documentation](https://www.jetbrains.com/help/pycharm/getting-started.html)."
   ],
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ce428793eb1a4297"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T07:51:41.501200900Z",
     "start_time": "2026-02-06T07:50:43.091978700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "url1 = \"https://raw.githubusercontent.com/Radwa-Ayman239/MenueEngineering/refs/heads/main/Data%20Analysis%20/Datasets/dim_add_on_categories_cleaned.csv\"\n",
    "url2 = \"https://raw.githubusercontent.com/Radwa-Ayman239/MenueEngineering/refs/heads/main/Data%20Analysis%20/Datasets/dim_add_ons_cleaned.csv\"\n",
    "url3 = \"https://raw.githubusercontent.com/Radwa-Ayman239/MenueEngineering/refs/heads/main/Data%20Analysis%20/Datasets/dim_items_cleaned.csv\"\n",
    "url4 = \"https://raw.githubusercontent.com/Radwa-Ayman239/MenueEngineering/refs/heads/main/Data%20Analysis%20/Datasets/dim_menu_item_add_on_categories_cleaned.csv\"\n",
    "url5 = \"https://raw.githubusercontent.com/Radwa-Ayman239/MenueEngineering/refs/heads/main/Data%20Analysis%20/Datasets/dim_menu_item_add_ons_cleaned.csv\"\n",
    "url6 = \"https://raw.githubusercontent.com/Radwa-Ayman239/MenueEngineering/refs/heads/main/Data%20Analysis%20/Datasets/dim_menu_items_cleaned.csv\"\n",
    "url7 = \"https://raw.githubusercontent.com/Radwa-Ayman239/MenueEngineering/refs/heads/main/Data%20Analysis%20/Datasets/dim_menu_sections_cleaned.csv\"\n",
    "url8 = \"https://raw.githubusercontent.com/Radwa-Ayman239/MenueEngineering/refs/heads/main/Data%20Analysis%20/Datasets/dim_sections_cleaned.csv\"\n",
    "# FIXED: Removed the extra dot after 'raw'\n",
    "url9 = \"https://raw.githubusercontent.com/Radwa-Ayman239/MenueEngineering/refs/heads/main/Data%20Analysis%20/Datasets/dim_users_cleaned.csv\"\n",
    "url10 = \"https://raw.githubusercontent.com/Radwa-Ayman239/MenueEngineering/refs/heads/main/Data%20Analysis%20/Datasets/menu_engineering_desc_cleaned.csv\"\n",
    "\n",
    "url11 = \"https://raw.githubusercontent.com/Radwa-Ayman239/MenueEngineering/refs/heads/main/Data%20Analysis%20/Datasets/menu_engineering_dogs.csv\"\n",
    "\n",
    "url12 = \"https://raw.githubusercontent.com/Radwa-Ayman239/MenueEngineering/refs/heads/main/Data%20Analysis%20/Datasets/menu_engineering_input_items.csv\"\n",
    "\n",
    "url13 = \"https://raw.githubusercontent.com/Radwa-Ayman239/MenueEngineering/refs/heads/main/Data%20Analysis%20/Datasets/menu_engineering_plowhorse_whatif.csv\"\n",
    "# Loading Data\n",
    "dim_add_on_categories_cleaned = pd.read_csv(url1)\n",
    "dim_add_ons_cleaned = pd.read_csv(url2)\n",
    "dim_items_cleaned = pd.read_csv(url3, low_memory=False)\n",
    "dim_menu_item_add_on_categories_cleaned = pd.read_csv(url4)\n",
    "dim_menu_item_add_ons_cleaned = pd.read_csv(url5)\n",
    "dim_menu_items_cleaned = pd.read_csv(url6)\n",
    "dim_menu_sections_cleaned = pd.read_csv(url7)\n",
    "dim_sections_cleaned = pd.read_csv(url8)\n",
    "dim_users_cleaned = pd.read_csv(url9, low_memory=False)\n",
    "analysis1  = pd.read_csv(url10)\n",
    "analysis2  = pd.read_csv(url11)\n",
    "analysis3  = pd.read_csv(url12)\n",
    "analysis4  = pd.read_csv(url13)\n",
    "\n",
    "\n"
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T08:05:32.415154300Z",
     "start_time": "2026-02-06T08:05:32.324849600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "transactions = (\n",
    "   dim_items_cleaned.groupby('purchases')['price']\n",
    "      .apply(list)\n",
    "      .tolist()\n",
    ")\n",
    "\n",
    "te = TransactionEncoder()\n",
    "te_array = te.fit(transactions).transform(transactions)\n",
    "\n",
    "basket = pd.DataFrame(te_array, columns=te.columns_)\n"
   ],
   "id": "cf63f3ea72fd313b",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T08:46:27.622692700Z",
     "start_time": "2026-02-06T08:46:27.575048300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from mlxtend.frequent_patterns import apriori\n",
    "\n",
    "frequent_itemsets = apriori(\n",
    "    basket,\n",
    "    min_support=0.15,\n",
    "    use_colnames=True\n",
    ")\n",
    "\n",
    "print(frequent_itemsets)\n"
   ],
   "id": "dfe759c10b680474",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    support           itemsets\n",
      "0  0.235357   frozenset({0.0})\n",
      "1  0.179269  frozenset({20.0})\n",
      "2  0.221157  frozenset({25.0})\n",
      "3  0.177494  frozenset({30.0})\n",
      "4  0.200923  frozenset({35.0})\n",
      "5  0.161519  frozenset({40.0})\n",
      "6  0.165779  frozenset({45.0})\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T08:03:30.660604800Z",
     "start_time": "2026-02-06T08:03:30.646228800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "rules = association_rules(\n",
    "    frequent_itemsets,\n",
    "    metric=\"confidence\",\n",
    "    min_threshold=0.70\n",
    ")\n"
   ],
   "id": "faa2af58100606ce",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T08:01:56.238722500Z",
     "start_time": "2026-02-06T08:01:56.209581200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "strong_rules = rules[\n",
    "    (rules['support'] >= 0.15) &\n",
    "    (rules['confidence'] >= 0.70)\n",
    "]\n",
    "\n",
    "strong_rules = strong_rules.sort_values(\n",
    "    by=['confidence', 'support'],\n",
    "    ascending=False\n",
    ")\n",
    "\n",
    "print(strong_rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']])\n"
   ],
   "id": "a64ed112e44c2e2b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [antecedents, consequents, support, confidence, lift]\n",
      "Index: []\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T08:42:11.819620700Z",
     "start_time": "2026-02-06T08:41:48.937690500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "\n",
    "# 1. Load Data with exact naming requested\n",
    "# (Replace the strings with your URLs as defined in your previous snippet)\n",
    "dim_add_ons_cleaned = pd.read_csv(url2)\n",
    "dim_items_cleaned = pd.read_csv(url3, low_memory=False)\n",
    "\n",
    "\n",
    "# We focus on the titles and their category groupings\n",
    "addons = dim_add_ons_cleaned[['id', 'title', 'category_id']].copy()\n",
    "\n",
    "#  Link Menu Items → Add-on Categories\n",
    "# \"We focus on items that have available add-ons\"\n",
    "item_addon_cats = dim_items_cleaned[['id', 'add_on_category_ids']].dropna().copy()\n",
    "\n",
    "# Split the pipe-separated IDs into a list\n",
    "item_addon_cats['category_id'] = (\n",
    "    item_addon_cats['add_on_category_ids']\n",
    "    .astype(str)\n",
    "    .str.split('|')\n",
    ")\n",
    "\n",
    "# Explode the list so each row is a unique Item-Category pair\n",
    "item_addon_cats = item_addon_cats.explode('category_id')\n",
    "item_addon_cats['category_id'] = pd.to_numeric(item_addon_cats['category_id'], errors='coerce')\n",
    "item_addon_cats = item_addon_cats.dropna()\n",
    "\n",
    "#  Attach Add-on Titles\n",
    "# This merges the item links with the actual add-on names\n",
    "item_addons = pd.merge(\n",
    "    item_addon_cats,\n",
    "    addons,\n",
    "    on='category_id',\n",
    "    how='inner',\n",
    "    suffixes=('_item_link', '')\n",
    ")\n",
    "\n",
    "\n",
    "#  Generate Transactions\n",
    "\n",
    "# Each \"Transaction\" is the set of add-ons available to one specific menu item\n",
    "transactions = (\n",
    "    item_addons\n",
    "    .groupby('id_item_link')['title']\n",
    "    .apply(lambda x: sorted(set(x)))\n",
    "    .tolist()\n",
    ")\n",
    "\n",
    "total_transactions = len(transactions)\n",
    "\n",
    "\n",
    "#  Calculate Frequencies (Manual Apriori)\n",
    "\n",
    "item_counts = {}\n",
    "pair_counts = {}\n",
    "\n",
    "for transaction in transactions:\n",
    "    for item in transaction:\n",
    "        item_counts[item] = item_counts.get(item, 0) + 1\n",
    "    for pair in combinations(transaction, 2):\n",
    "        pair = tuple(sorted(pair))\n",
    "        pair_counts[pair] = pair_counts.get(pair, 0) + 1\n",
    "\n",
    "# Build Association Rules\n",
    "\n",
    "# Filter by Support > 15% and Confidence > 70%\n",
    "rules = []\n",
    "\n",
    "for (a, b), ab_count in pair_counts.items():\n",
    "    support_ab = ab_count / total_transactions\n",
    "    support_a = item_counts[a] / total_transactions\n",
    "    support_b = item_counts[b] / total_transactions\n",
    "\n",
    "    # Direction: A → B\n",
    "    conf_ab = support_ab / support_a\n",
    "    if support_ab >= 0.15 and conf_ab >= 0.70:\n",
    "        rules.append({\n",
    "            'antecedent': a,\n",
    "            'consequent': b,\n",
    "            'support': support_ab,\n",
    "            'confidence': conf_ab,\n",
    "            'lift': support_ab / (support_a * support_b)\n",
    "        })\n",
    "\n",
    "    # Direction: B → A\n",
    "    conf_ba = support_ab / support_b\n",
    "    if support_ab >= 0.15 and conf_ba >= 0.70:\n",
    "        rules.append({\n",
    "            'antecedent': b,\n",
    "            'consequent': a,\n",
    "            'support': support_ab,\n",
    "            'confidence': conf_ba,\n",
    "            'lift': support_ab / (support_a * support_b)\n",
    "        })\n",
    "\n",
    "#  Final Output & Export\n",
    "\n",
    "strong_rules = (\n",
    "    pd.DataFrame(rules)\n",
    "    .sort_values(['confidence', 'support'], ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Strong Add-on Associations Found:\")\n",
    "print(strong_rules.head(10))\n",
    "\n",
    "# Save to CSV\n",
    "strong_rules.to_csv('strong_rules.csv', index=False)\n",
    "strong_rules.to_csv('strong_addon_rules.csv', index=False)"
   ],
   "id": "1e6fc76316e63a14",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strong Add-on Associations Found:\n",
      "  antecedent  consequent   support  confidence      lift\n",
      "0     Pølser       Bacon  0.194567    1.000000  3.296489\n",
      "1     Pølser      Skinke  0.194567    1.000000  3.394523\n",
      "2  Tacosauce  Champignon  0.190092    1.000000  2.895784\n",
      "3  Tacosauce         Løg  0.190092    1.000000  2.883679\n",
      "4       Majs      Ananas  0.273352    0.998389  2.859284\n",
      "5     Pølser      Ananas  0.194252    0.998380  2.859260\n",
      "6   Kødsauce  Champignon  0.302534    0.995025  2.881377\n",
      "7  Oksefilet  Champignon  0.199168    0.994336  2.879382\n",
      "8  Oksefilet       Kebab  0.199168    0.994336  2.971024\n",
      "9  Spaghetti         Løg  0.286020    0.989318  2.852874\n"
     ]
    }
   ],
   "execution_count": 25
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
