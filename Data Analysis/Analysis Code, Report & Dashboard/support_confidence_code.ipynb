{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# This is a sample Jupyter Notebook\n",
    "\n",
    "Below is an example of a code cell. \n",
    "Put your cursor into the cell and press Shift+Enter to execute it and select the next one, or click 'Run Cell' button.\n",
    "\n",
    "Press Double Shift to search everywhere for classes, files, tool windows, actions, and settings.\n",
    "\n",
    "To learn more about Jupyter Notebooks in PyCharm, see [help](https://www.jetbrains.com/help/pycharm/ipython-notebook-support.html).\n",
    "For an overview of PyCharm, go to Help -> Learn IDE features or refer to [our documentation](https://www.jetbrains.com/help/pycharm/getting-started.html)."
   ],
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ce428793eb1a4297"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Items and add_ons",
   "id": "b8c3f5f976543667"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T10:41:23.525618200Z",
     "start_time": "2026-02-06T10:40:57.676939100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "\n",
    "url2 = \"https://raw.githubusercontent.com/Radwa-Ayman239/MenueEngineering/refs/heads/main/Data%20Analysis/Datasets/dim_add_ons_cleaned.csv\"\n",
    "dim_add_ons_cleaned = pd.read_csv(url2)\n",
    "url3 = \"https://raw.githubusercontent.com/Radwa-Ayman239/MenueEngineering/refs/heads/main/Data%20Analysis/Datasets/dim_items_cleaned.csv\"\n",
    "\n",
    "\n",
    "dim_items_cleaned = pd.read_csv(url3, low_memory=False)\n",
    "\n",
    "\n",
    "\n",
    "# We focus on the titles and their category groupings\n",
    "addons = dim_add_ons_cleaned[['id', 'title', 'category_id']].copy()\n",
    "\n",
    "#  Link Menu Items → Add-on Categories\n",
    "# \"We focus on items that have available add-ons\"\n",
    "item_addon_cats = dim_items_cleaned[['id', 'add_on_category_ids']].dropna().copy()\n",
    "\n",
    "# Split the pipe-separated IDs into a list\n",
    "item_addon_cats['category_id'] = (\n",
    "    item_addon_cats['add_on_category_ids']\n",
    "    .astype(str)\n",
    "    .str.split('|')\n",
    ")\n",
    "\n",
    "# Explode the list so each row is a unique Item-Category pair\n",
    "item_addon_cats = item_addon_cats.explode('category_id')\n",
    "item_addon_cats['category_id'] = pd.to_numeric(item_addon_cats['category_id'], errors='coerce')\n",
    "item_addon_cats = item_addon_cats.dropna()\n",
    "\n",
    "#  Attach Add-on Titles\n",
    "# This merges the item links with the actual add-on names\n",
    "item_addons = pd.merge(\n",
    "    item_addon_cats,\n",
    "    addons,\n",
    "    on='category_id',\n",
    "    how='inner',\n",
    "    suffixes=('_item_link', '')\n",
    ")\n",
    "\n",
    "\n",
    "#  Generate Transactions\n",
    "\n",
    "# Each \"Transaction\" is the set of add-ons available to one specific menu item\n",
    "transactions = (\n",
    "    item_addons\n",
    "    .groupby('id_item_link')['title']\n",
    "    .apply(lambda x: sorted(set(x)))\n",
    "    .tolist()\n",
    ")\n",
    "\n",
    "total_transactions = len(transactions)\n",
    "\n",
    "\n",
    "#  Calculate Frequencies\n",
    "\n",
    "item_counts = {}\n",
    "pair_counts = {}\n",
    "\n",
    "for transaction in transactions:\n",
    "    for item in transaction:\n",
    "        item_counts[item] = item_counts.get(item, 0) + 1\n",
    "    for pair in combinations(transaction, 2):\n",
    "        pair = tuple(sorted(pair))\n",
    "        pair_counts[pair] = pair_counts.get(pair, 0) + 1\n",
    "\n",
    "# Build Association Rules\n",
    "\n",
    "# Filter by Support > 15% and Confidence > 70%\n",
    "rules = []\n",
    "\n",
    "for (a, b), ab_count in pair_counts.items():\n",
    "    support_ab = ab_count / total_transactions\n",
    "    support_a = item_counts[a] / total_transactions\n",
    "    support_b = item_counts[b] / total_transactions\n",
    "\n",
    "    # Direction: A → B\n",
    "    conf_ab = support_ab / support_a\n",
    "    if support_ab >= 0.15 and conf_ab >= 0.70:\n",
    "        rules.append({\n",
    "            'antecedent': a,\n",
    "            'consequent': b,\n",
    "            'support': support_ab,\n",
    "            'confidence': conf_ab,\n",
    "            'lift': support_ab / (support_a * support_b)\n",
    "        })\n",
    "\n",
    "    # Direction: B → A\n",
    "    conf_ba = support_ab / support_b\n",
    "    if support_ab >= 0.15 and conf_ba >= 0.70:\n",
    "        rules.append({\n",
    "            'antecedent': b,\n",
    "            'consequent': a,\n",
    "            'support': support_ab,\n",
    "            'confidence': conf_ba,\n",
    "            'lift': support_ab / (support_a * support_b)\n",
    "        })\n",
    "\n",
    "#  Final Output & Export\n",
    "\n",
    "strong_rules = (\n",
    "    pd.DataFrame(rules)\n",
    "    .sort_values(['confidence', 'support'], ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Strong Add-on Associations Found:\")\n",
    "print(strong_rules.head(10))\n",
    "\n",
    "# Save to CSV\n",
    "strong_rules.to_csv('strong_rules.csv', index=False)\n",
    "strong_rules.to_csv('strong_addon_rules.csv', index=False)"
   ],
   "id": "1e6fc76316e63a14",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strong Add-on Associations Found:\n",
      "  antecedent  consequent   support  confidence      lift\n",
      "0     Pølser       Bacon  0.194567    1.000000  3.296489\n",
      "1     Pølser      Skinke  0.194567    1.000000  3.394523\n",
      "2  Tacosauce  Champignon  0.190092    1.000000  2.895784\n",
      "3  Tacosauce         Løg  0.190092    1.000000  2.883679\n",
      "4       Majs      Ananas  0.273352    0.998389  2.859284\n",
      "5     Pølser      Ananas  0.194252    0.998380  2.859260\n",
      "6   Kødsauce  Champignon  0.302534    0.995025  2.881377\n",
      "7  Oksefilet  Champignon  0.199168    0.994336  2.879382\n",
      "8  Oksefilet       Kebab  0.199168    0.994336  2.971024\n",
      "9  Spaghetti         Løg  0.286020    0.989318  2.852874\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T10:57:03.342636300Z",
     "start_time": "2026-02-06T10:56:36.138352500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "\n",
    "url2 = \"https://raw.githubusercontent.com/Radwa-Ayman239/MenueEngineering/refs/heads/main/Data%20Analysis/Datasets/dim_add_ons_cleaned.csv\"\n",
    "dim_add_ons_cleaned = pd.read_csv(url2)\n",
    "url3 = \"https://raw.githubusercontent.com/Radwa-Ayman239/MenueEngineering/refs/heads/main/Data%20Analysis/Datasets/dim_items_cleaned.csv\"\n",
    "\n",
    "\n",
    "dim_items_cleaned = pd.read_csv(url3, low_memory=False)\n",
    "\n",
    "\n",
    "# 2. Extract Titles and Categories\n",
    "addons = dim_add_ons_cleaned[['id', 'title', 'category_id']].copy()\n",
    "item_addon_cats = dim_items_cleaned[['id', 'add_on_category_ids']].dropna().copy()\n",
    "\n",
    "# 3. Process IDs\n",
    "item_addon_cats['category_id'] = item_addon_cats['add_on_category_ids'].astype(str).str.split('|')\n",
    "item_addon_cats = item_addon_cats.explode('category_id')\n",
    "item_addon_cats['category_id'] = pd.to_numeric(item_addon_cats['category_id'], errors='coerce')\n",
    "item_addon_cats = item_addon_cats.dropna()\n",
    "\n",
    "# 4. Merge to Link Items to Add-on Names\n",
    "item_addons = pd.merge(\n",
    "    item_addon_cats,\n",
    "    addons,\n",
    "    on='category_id',\n",
    "    how='inner',\n",
    "    suffixes=('_item_link', '')\n",
    ")\n",
    "\n",
    "# 5. Generate Transactions (Add-on groups per menu item)\n",
    "transactions = (\n",
    "    item_addons\n",
    "    .groupby('id_item_link')['title']\n",
    "    .apply(lambda x: sorted(set(x)))\n",
    "    .tolist()\n",
    ")\n",
    "\n",
    "total_transactions = len(transactions)\n",
    "\n",
    "# 6. Calculate Frequencies\n",
    "item_counts = {}\n",
    "pair_counts = {}\n",
    "\n",
    "for transaction in transactions:\n",
    "    for item in transaction:\n",
    "        item_counts[item] = item_counts.get(item, 0) + 1\n",
    "    for pair in combinations(transaction, 2):\n",
    "        pair = tuple(sorted(pair))\n",
    "        pair_counts[pair] = pair_counts.get(pair, 0) + 1\n",
    "\n",
    "# 7. Build Association Rules\n",
    "rules = []\n",
    "for (a, b), ab_count in pair_counts.items():\n",
    "    support_ab = ab_count / total_transactions\n",
    "    support_a = item_counts[a] / total_transactions\n",
    "    support_b = item_counts[b] / total_transactions\n",
    "\n",
    "    # A -> B\n",
    "    conf_ab = support_ab / support_a\n",
    "    if support_ab >= 0.15 and conf_ab >= 0.70:\n",
    "        rules.append({\n",
    "            'antecedent': a,\n",
    "            'consequent': b,\n",
    "            'support': support_ab,\n",
    "            'confidence': conf_ab,\n",
    "            'lift': support_ab / (support_a * support_b)\n",
    "        })\n",
    "\n",
    "    # B -> A\n",
    "    conf_ba = support_ab / support_b\n",
    "    if support_ab >= 0.15 and conf_ba >= 0.70:\n",
    "        rules.append({\n",
    "            'antecedent': b,\n",
    "            'consequent': a,\n",
    "            'support': support_ab,\n",
    "            'confidence': conf_ba,\n",
    "            'lift': support_ab / (support_a * support_b)\n",
    "        })\n",
    "\n",
    "# 8. Final Export\n",
    "strong_rules = pd.DataFrame(rules).sort_values(['confidence', 'support'], ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Save the results to CSV files\n",
    "strong_rules.to_csv('strong_addon_rules.csv', index=False)\n",
    "\n",
    "print(f\"Success! Analyzed {total_transactions} items.\")\n",
    "print(\"The file 'strong_addon_rules.csv' has been saved to your current folder.\")"
   ],
   "id": "b321b411970e1671",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! Analyzed 15866 items.\n",
      "The file 'strong_addon_rules.csv' has been saved to your current folder.\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T10:44:08.343303500Z",
     "start_time": "2026-02-06T10:43:48.795149800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "\n",
    "url3 = \"https://raw.githubusercontent.com/Radwa-Ayman239/MenueEngineering/refs/heads/main/Data%20Analysis/Datasets/dim_items_cleaned.csv\"\n",
    "\n",
    "\n",
    "dim_items_cleaned = pd.read_csv(url3, low_memory=False)\n",
    "\n",
    "\n",
    "df = dim_items_cleaned[['title', 'add_on_category_ids']].dropna()\n",
    "\n",
    "# Split the pipe-separated IDs and explode them\n",
    "df['cat_list'] = df['add_on_category_ids'].astype(str).str.split('|')\n",
    "exploded = df.explode('cat_list')\n",
    "\n",
    "# 3. Create \"Category Baskets\"\n",
    "# Each Category ID acts as a \"basket\" containing all items that use it\n",
    "transactions = (\n",
    "    exploded.groupby('cat_list')['title']\n",
    "    .apply(lambda x: sorted(set(x)))\n",
    "    .tolist()\n",
    ")\n",
    "\n",
    "# Filter out categories that only apply to one item\n",
    "transactions = [t for t in transactions if len(t) > 1]\n",
    "total_trans = len(transactions)\n",
    "\n",
    "# 4. Manual Association Logic\n",
    "item_counts = {}\n",
    "pair_counts = {}\n",
    "\n",
    "for basket in transactions:\n",
    "    for item in basket:\n",
    "        item_counts[item] = item_counts.get(item, 0) + 1\n",
    "    for pair in combinations(basket, 2):\n",
    "        pair = tuple(sorted(pair))\n",
    "        pair_counts[pair] = pair_counts.get(pair, 0) + 1\n",
    "\n",
    "# 5. Build the Rules\n",
    "rules = []\n",
    "for (a, b), count in pair_counts.items():\n",
    "    support = count / total_trans\n",
    "    conf_a_to_b = count / item_counts[a]\n",
    "\n",
    "    # We use a lower support (1%) because menu items are more diverse than ingredients\n",
    "    if support >= 0.01 and conf_a_to_b >= 0.50:\n",
    "        rules.append({\n",
    "            'item_a': a,\n",
    "            'item_b': b,\n",
    "            'support': support,\n",
    "            'confidence': conf_a_to_b,\n",
    "            'lift': (count / total_trans) / ((item_counts[a]/total_trans) * (item_counts[b]/total_trans))\n",
    "        })\n",
    "\n",
    "# 6. Final Output with Safety Check\n",
    "if len(rules) > 0:\n",
    "    df_rules = pd.DataFrame(rules).sort_values(['confidence', 'support'], ascending=False)\n",
    "    print(\"Strong Item-to-Item Structural Associations Found:\")\n",
    "    print(df_rules.head(10))\n",
    "    df_rules.to_csv('item_structural_associations.csv', index=False)\n",
    "else:\n",
    "    print(\"No item associations found. Try lowering the support threshold.\")"
   ],
   "id": "c98f0aab7b39aef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strong Item-to-Item Structural Associations Found:\n",
      "                       item_a                         item_b   support  \\\n",
      "16                   Coleslaw                Corn on the cob  0.039749   \n",
      "13              Chicken Wings                       Coleslaw  0.039226   \n",
      "14              Chicken Wings                Corn on the cob  0.039226   \n",
      "36  Google Pixel 5 Reparation     Google Pixel 5A Reparation  0.018828   \n",
      "37  Google Pixel 5 Reparation  Google Pixel 6 Pro Reparation  0.018828   \n",
      "38  Google Pixel 5 Reparation      Google Pixel 6 Reparation  0.018828   \n",
      "39  Google Pixel 5 Reparation     Google Pixel 6A Reparation  0.018828   \n",
      "40  Google Pixel 5 Reparation  Google Pixel 7 Pro Reparation  0.018828   \n",
      "41  Google Pixel 5 Reparation      Google Pixel 7 Reparation  0.018828   \n",
      "42  Google Pixel 5 Reparation     Google Pixel 7A Reparation  0.018828   \n",
      "\n",
      "    confidence       lift  \n",
      "16         1.0  25.157895  \n",
      "13         1.0  25.157895  \n",
      "14         1.0  25.157895  \n",
      "36         1.0  53.111111  \n",
      "37         1.0  53.111111  \n",
      "38         1.0  53.111111  \n",
      "39         1.0  53.111111  \n",
      "40         1.0  53.111111  \n",
      "41         1.0  53.111111  \n",
      "42         1.0  53.111111  \n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T10:53:49.761863100Z",
     "start_time": "2026-02-06T10:53:28.200072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "\n",
    "\n",
    "url3 = \"https://raw.githubusercontent.com/Radwa-Ayman239/MenueEngineering/refs/heads/main/Data%20Analysis/Datasets/dim_items_cleaned.csv\"\n",
    "\n",
    "\n",
    "dim_items_cleaned = pd.read_csv(url3, low_memory=False)\n",
    "\n",
    "# 1. Group items by their shared Add-on Categories\n",
    "df = dim_items_cleaned[['title', 'add_on_category_ids']].dropna()\n",
    "df['cat_list'] = df['add_on_category_ids'].astype(str).str.split('|')\n",
    "exploded = df.explode('cat_list')\n",
    "\n",
    "transactions = (\n",
    "    exploded.groupby('cat_list')['title']\n",
    "    .apply(lambda x: sorted(set(x)))\n",
    "    .tolist()\n",
    ")\n",
    "\n",
    "# # Filter groups and count occurrences\n",
    "transactions = [t for t in transactions if len(t) > 1]\n",
    "total_trans = len(transactions)\n",
    "item_counts = {}\n",
    "pair_counts = {}\n",
    "\n",
    "for basket in transactions:\n",
    "    for item in basket:\n",
    "        item_counts[item] = item_counts.get(item, 0) + 1\n",
    "    for pair in combinations(basket, 2):\n",
    "        pair = tuple(sorted(pair))\n",
    "        pair_counts[pair] = pair_counts.get(pair, 0) + 1\n",
    "\n",
    "# Calculate Confidence and Save\n",
    "rules = []\n",
    "for (a, b), count in pair_counts.items():\n",
    "    rules.append({\n",
    "        'item_a': a,\n",
    "        'item_b': b,\n",
    "        'support': count/total_trans,\n",
    "        'confidence': count/item_counts[a]\n",
    "    })\n",
    "\n",
    "df_item_rules = pd.DataFrame(rules).sort_values('confidence', ascending=False)\n",
    "\n",
    "# THIS LINE CREATES THE FILE IN YOUR FOLDER\n",
    "df_item_rules.to_csv('item_item_structural_associations.csv', index=False)\n",
    "print(\"File 'item_item_structural_associations.csv' has been saved to your folder.\")"
   ],
   "id": "8f855e2b66c805c4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'item_item_structural_associations.csv' has been saved to your folder.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3f18ac1edcbf770a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
